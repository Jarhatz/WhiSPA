{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    WhisperProcessor\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "from config import WhiSBERTConfig, CACHE_DIR, CHECKPOINT_DIR\n",
    "from model import WhiSBERTModel\n",
    "from data import AudioDataset, collate_train\n",
    "from train import load_models\n",
    "from utils import (\n",
    "    mean_pooling,\n",
    "    cos_sim_loss,\n",
    "    sim_clr_loss,\n",
    "    norm_temp_ce_loss\n",
    ")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config = WhiSBERTConfig(\n",
    "    whisper_model_id='openai/whisper-base',\n",
    "    pooling_mode='mean',\n",
    "    # use_sbert_encoder=True,\n",
    "    n_new_dims=7,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    device='cpu'\n",
    ")\n",
    "processor, whisbert, tokenizer, sbert = load_models(config, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing AudioDataset...\n",
      "\tTotal dataset size (N): 50352\n",
      "\tTraining dataset size (N): 40281\n",
      "\tValidation dataset size (N): 10071\n"
     ]
    }
   ],
   "source": [
    "print('Preprocessing AudioDataset...')\n",
    "dataset = AudioDataset(processor)\n",
    "mini_size = int(0.1 * len(dataset))\n",
    "drop_size = len(dataset) - mini_size\n",
    "mini_dataset, _ = torch.utils.data.random_split(dataset, [mini_size, drop_size])\n",
    "\n",
    "# Calculate lengths for the train/val split (80:20)\n",
    "total_size = len(mini_dataset)\n",
    "train_size = int(0.8 * total_size)  # 80% for training\n",
    "val_size = total_size - train_size  # 20% for validation\n",
    "# Perform the split\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(mini_dataset, [train_size, val_size])\n",
    "print(f'\\tTotal dataset size (N): {total_size}')\n",
    "print(f'\\tTraining dataset size (N): {train_size}')\n",
    "print(f'\\tValidation dataset size (N): {val_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    shuffle=config.shuffle,\n",
    "    collate_fn=collate_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 80, 3000])\n",
      "8\n",
      "torch.Size([8, 7])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(data_loader))\n",
    "print(batch['audio_inputs'].shape)\n",
    "print(len(batch['message']))\n",
    "print(batch['outcomes'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 26])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(batch['message'], padding=True, truncation=True, return_tensors='pt').to(config.device)\n",
    "encoded_input['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 26, 384])\n",
      "torch.Size([8, 384])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sbert_output = sbert(**encoded_input)\n",
    "print(sbert_output.last_hidden_state.shape)\n",
    "sentence_embeddings = mean_pooling(sbert_output.last_hidden_state, encoded_input['attention_mask'])\n",
    "print(sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 23])\n",
      "torch.Size([8, 23])\n"
     ]
    }
   ],
   "source": [
    "# Whisper-based tokenization\n",
    "with torch.no_grad():\n",
    "    outputs = processor.tokenizer(\n",
    "        batch['message'],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors='pt'\n",
    "    ).to(config.device)\n",
    "print(outputs['input_ids'].shape)\n",
    "print(outputs['attention_mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 391])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get WhiSBERT's MEAN/LAST token\n",
    "whis_embs = whisbert(\n",
    "    batch['audio_inputs'].to(config.device),\n",
    "    outputs['input_ids'],\n",
    "    outputs['attention_mask']\n",
    ")\n",
    "whis_embs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
