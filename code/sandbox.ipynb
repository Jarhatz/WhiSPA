{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    WhisperProcessor\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "from config import WhiSBERTConfig, CACHE_DIR, CHECKPOINT_DIR\n",
    "from model import WhiSBERTModel\n",
    "from data import AudioDataset, collate_train\n",
    "from train import load_models\n",
    "from utils import (\n",
    "    mean_pooling,\n",
    "    cos_sim_loss,\n",
    "    sim_clr_loss,\n",
    "    norm_temp_ce_loss\n",
    ")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>segment_filename</th>\n",
       "      <th>segment_message</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>ope</th>\n",
       "      <th>agr</th>\n",
       "      <th>ext</th>\n",
       "      <th>con</th>\n",
       "      <th>neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PP572</td>\n",
       "      <td>PP572_0_1</td>\n",
       "      <td>HiTOP_PP572_07062023_AA - 0001.wav</td>\n",
       "      <td>I've never been an inpatient, but I've had ou...</td>\n",
       "      <td>5.141840</td>\n",
       "      <td>2.158170</td>\n",
       "      <td>9.027416</td>\n",
       "      <td>1.830520</td>\n",
       "      <td>-2.399522</td>\n",
       "      <td>-5.423723</td>\n",
       "      <td>2.477061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP572</td>\n",
       "      <td>PP572_0_2</td>\n",
       "      <td>HiTOP_PP572_07062023_AA - 0002.wav</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006014</td>\n",
       "      <td>0.209157</td>\n",
       "      <td>0.531530</td>\n",
       "      <td>0.181332</td>\n",
       "      <td>-0.120239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP572</td>\n",
       "      <td>PP572_0_4</td>\n",
       "      <td>HiTOP_PP572_07062023_AA - 0004.wav</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006014</td>\n",
       "      <td>0.209157</td>\n",
       "      <td>0.531530</td>\n",
       "      <td>0.181332</td>\n",
       "      <td>-0.120239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP572</td>\n",
       "      <td>PP572_0_8</td>\n",
       "      <td>HiTOP_PP572_07062023_AA - 0008.wav</td>\n",
       "      <td>I like to go out with friends.</td>\n",
       "      <td>5.589249</td>\n",
       "      <td>2.401895</td>\n",
       "      <td>0.018631</td>\n",
       "      <td>1.967006</td>\n",
       "      <td>1.614968</td>\n",
       "      <td>0.604015</td>\n",
       "      <td>0.321846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP572</td>\n",
       "      <td>PP572_0_9</td>\n",
       "      <td>HiTOP_PP572_07062023_AA - 0009.wav</td>\n",
       "      <td>I'm a music major and I don't really get much...</td>\n",
       "      <td>4.117138</td>\n",
       "      <td>2.018602</td>\n",
       "      <td>5.752272</td>\n",
       "      <td>0.132441</td>\n",
       "      <td>-0.953059</td>\n",
       "      <td>-5.101045</td>\n",
       "      <td>5.423269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571415</th>\n",
       "      <td>P692</td>\n",
       "      <td>P692_0_1186</td>\n",
       "      <td>P692_08062024_BB_12760_S - 1186.wav</td>\n",
       "      <td>No, I know when enough's enough.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006014</td>\n",
       "      <td>0.209157</td>\n",
       "      <td>0.531530</td>\n",
       "      <td>0.181332</td>\n",
       "      <td>-0.120239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571416</th>\n",
       "      <td>P692</td>\n",
       "      <td>P692_0_1187</td>\n",
       "      <td>P692_08062024_BB_12760_S - 1187.wav</td>\n",
       "      <td>This is some really strange weather will happen.</td>\n",
       "      <td>5.143191</td>\n",
       "      <td>2.198984</td>\n",
       "      <td>9.212935</td>\n",
       "      <td>2.315006</td>\n",
       "      <td>-7.801025</td>\n",
       "      <td>-7.491872</td>\n",
       "      <td>3.579342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571417</th>\n",
       "      <td>P692</td>\n",
       "      <td>P692_0_1188</td>\n",
       "      <td>P692_08062024_BB_12760_S - 1188.wav</td>\n",
       "      <td>The sun is shining and it's thundering.</td>\n",
       "      <td>5.014759</td>\n",
       "      <td>2.366074</td>\n",
       "      <td>11.030973</td>\n",
       "      <td>1.020247</td>\n",
       "      <td>-1.806953</td>\n",
       "      <td>-4.181623</td>\n",
       "      <td>-5.101836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571418</th>\n",
       "      <td>P692</td>\n",
       "      <td>P692_0_1191</td>\n",
       "      <td>P692_08062024_BB_12760_S - 1191.wav</td>\n",
       "      <td>are you in New York too?</td>\n",
       "      <td>5.862231</td>\n",
       "      <td>2.522707</td>\n",
       "      <td>-0.677049</td>\n",
       "      <td>-2.860874</td>\n",
       "      <td>1.331570</td>\n",
       "      <td>1.301145</td>\n",
       "      <td>0.250222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571419</th>\n",
       "      <td>P692</td>\n",
       "      <td>P692_0_1192</td>\n",
       "      <td>P692_08062024_BB_12760_S - 1192.wav</td>\n",
       "      <td>Yep, yeah, it's horrible.</td>\n",
       "      <td>3.413187</td>\n",
       "      <td>3.460847</td>\n",
       "      <td>1.901616</td>\n",
       "      <td>-9.796453</td>\n",
       "      <td>-4.793876</td>\n",
       "      <td>-8.136401</td>\n",
       "      <td>11.325629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>571420 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   segment_id                     segment_filename  \\\n",
       "0        PP572    PP572_0_1   HiTOP_PP572_07062023_AA - 0001.wav   \n",
       "1        PP572    PP572_0_2   HiTOP_PP572_07062023_AA - 0002.wav   \n",
       "2        PP572    PP572_0_4   HiTOP_PP572_07062023_AA - 0004.wav   \n",
       "3        PP572    PP572_0_8   HiTOP_PP572_07062023_AA - 0008.wav   \n",
       "4        PP572    PP572_0_9   HiTOP_PP572_07062023_AA - 0009.wav   \n",
       "...        ...          ...                                  ...   \n",
       "571415    P692  P692_0_1186  P692_08062024_BB_12760_S - 1186.wav   \n",
       "571416    P692  P692_0_1187  P692_08062024_BB_12760_S - 1187.wav   \n",
       "571417    P692  P692_0_1188  P692_08062024_BB_12760_S - 1188.wav   \n",
       "571418    P692  P692_0_1191  P692_08062024_BB_12760_S - 1191.wav   \n",
       "571419    P692  P692_0_1192  P692_08062024_BB_12760_S - 1192.wav   \n",
       "\n",
       "                                          segment_message   valence   arousal  \\\n",
       "0        I've never been an inpatient, but I've had ou...  5.141840  2.158170   \n",
       "1                                                   Okay.       NaN       NaN   \n",
       "2                                                    Yes.       NaN       NaN   \n",
       "3                          I like to go out with friends.  5.589249  2.401895   \n",
       "4        I'm a music major and I don't really get much...  4.117138  2.018602   \n",
       "...                                                   ...       ...       ...   \n",
       "571415                   No, I know when enough's enough.       NaN       NaN   \n",
       "571416   This is some really strange weather will happen.  5.143191  2.198984   \n",
       "571417            The sun is shining and it's thundering.  5.014759  2.366074   \n",
       "571418                           are you in New York too?  5.862231  2.522707   \n",
       "571419                          Yep, yeah, it's horrible.  3.413187  3.460847   \n",
       "\n",
       "              ope       agr       ext       con        neu  \n",
       "0        9.027416  1.830520 -2.399522 -5.423723   2.477061  \n",
       "1       -0.006014  0.209157  0.531530  0.181332  -0.120239  \n",
       "2       -0.006014  0.209157  0.531530  0.181332  -0.120239  \n",
       "3        0.018631  1.967006  1.614968  0.604015   0.321846  \n",
       "4        5.752272  0.132441 -0.953059 -5.101045   5.423269  \n",
       "...           ...       ...       ...       ...        ...  \n",
       "571415  -0.006014  0.209157  0.531530  0.181332  -0.120239  \n",
       "571416   9.212935  2.315006 -7.801025 -7.491872   3.579342  \n",
       "571417  11.030973  1.020247 -1.806953 -4.181623  -5.101836  \n",
       "571418  -0.677049 -2.860874  1.331570  1.301145   0.250222  \n",
       "571419   1.901616 -9.796453 -4.793876 -8.136401  11.325629  \n",
       "\n",
       "[571420 rows x 11 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitop_segments_df = pd.read_csv('/cronus_data/rrao/hitop/segment_outcomes.csv')\n",
    "hitop_segments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>f000</th>\n",
       "      <th>f001</th>\n",
       "      <th>f002</th>\n",
       "      <th>f003</th>\n",
       "      <th>f004</th>\n",
       "      <th>f005</th>\n",
       "      <th>f006</th>\n",
       "      <th>f007</th>\n",
       "      <th>f008</th>\n",
       "      <th>...</th>\n",
       "      <th>f374</th>\n",
       "      <th>f375</th>\n",
       "      <th>f376</th>\n",
       "      <th>f377</th>\n",
       "      <th>f378</th>\n",
       "      <th>f379</th>\n",
       "      <th>f380</th>\n",
       "      <th>f381</th>\n",
       "      <th>f382</th>\n",
       "      <th>f383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PP572_0_1</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>0.019323</td>\n",
       "      <td>0.007478</td>\n",
       "      <td>0.041222</td>\n",
       "      <td>-0.104351</td>\n",
       "      <td>-0.034637</td>\n",
       "      <td>-0.040082</td>\n",
       "      <td>0.048785</td>\n",
       "      <td>-0.049720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>0.035958</td>\n",
       "      <td>0.039362</td>\n",
       "      <td>-0.010150</td>\n",
       "      <td>-0.011600</td>\n",
       "      <td>0.040785</td>\n",
       "      <td>0.031120</td>\n",
       "      <td>0.030377</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>-0.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP572_0_2</td>\n",
       "      <td>0.063735</td>\n",
       "      <td>-0.090145</td>\n",
       "      <td>0.076856</td>\n",
       "      <td>0.016580</td>\n",
       "      <td>-0.015392</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>-0.014066</td>\n",
       "      <td>-0.021347</td>\n",
       "      <td>-0.007709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104106</td>\n",
       "      <td>0.071222</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>0.048025</td>\n",
       "      <td>0.031107</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>0.102623</td>\n",
       "      <td>0.039707</td>\n",
       "      <td>0.047844</td>\n",
       "      <td>0.039239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP572_0_4</td>\n",
       "      <td>-0.009147</td>\n",
       "      <td>0.044874</td>\n",
       "      <td>0.095438</td>\n",
       "      <td>0.088864</td>\n",
       "      <td>0.026287</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>-0.001537</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008186</td>\n",
       "      <td>-0.041032</td>\n",
       "      <td>-0.010027</td>\n",
       "      <td>0.012494</td>\n",
       "      <td>0.034509</td>\n",
       "      <td>0.038356</td>\n",
       "      <td>0.064894</td>\n",
       "      <td>0.012516</td>\n",
       "      <td>0.084423</td>\n",
       "      <td>0.010010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP572_0_8</td>\n",
       "      <td>0.019812</td>\n",
       "      <td>-0.029717</td>\n",
       "      <td>0.070069</td>\n",
       "      <td>0.034346</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.164560</td>\n",
       "      <td>0.050357</td>\n",
       "      <td>-0.008711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014106</td>\n",
       "      <td>0.020565</td>\n",
       "      <td>-0.031883</td>\n",
       "      <td>0.069381</td>\n",
       "      <td>-0.025189</td>\n",
       "      <td>-0.059564</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.010954</td>\n",
       "      <td>0.017886</td>\n",
       "      <td>-0.061186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP572_0_9</td>\n",
       "      <td>0.073630</td>\n",
       "      <td>-0.007963</td>\n",
       "      <td>0.084720</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.041942</td>\n",
       "      <td>0.036758</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.054233</td>\n",
       "      <td>0.024699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025823</td>\n",
       "      <td>-0.039665</td>\n",
       "      <td>0.044497</td>\n",
       "      <td>0.060275</td>\n",
       "      <td>-0.090286</td>\n",
       "      <td>-0.095973</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>-0.100035</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>-0.068029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571415</th>\n",
       "      <td>P692_0_1186</td>\n",
       "      <td>0.021623</td>\n",
       "      <td>-0.037660</td>\n",
       "      <td>0.036766</td>\n",
       "      <td>-0.066743</td>\n",
       "      <td>-0.012067</td>\n",
       "      <td>-0.032461</td>\n",
       "      <td>0.029833</td>\n",
       "      <td>0.037347</td>\n",
       "      <td>0.053613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062468</td>\n",
       "      <td>0.008806</td>\n",
       "      <td>-0.059389</td>\n",
       "      <td>0.014321</td>\n",
       "      <td>-0.085285</td>\n",
       "      <td>0.089797</td>\n",
       "      <td>-0.038306</td>\n",
       "      <td>0.023783</td>\n",
       "      <td>-0.013505</td>\n",
       "      <td>0.037073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571416</th>\n",
       "      <td>P692_0_1187</td>\n",
       "      <td>-0.013937</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>0.013619</td>\n",
       "      <td>0.048789</td>\n",
       "      <td>-0.042261</td>\n",
       "      <td>0.006820</td>\n",
       "      <td>-0.012841</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046992</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.058689</td>\n",
       "      <td>-0.005668</td>\n",
       "      <td>0.034324</td>\n",
       "      <td>0.031395</td>\n",
       "      <td>-0.075359</td>\n",
       "      <td>0.046120</td>\n",
       "      <td>-0.029264</td>\n",
       "      <td>0.046044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571417</th>\n",
       "      <td>P692_0_1188</td>\n",
       "      <td>-0.041092</td>\n",
       "      <td>0.032440</td>\n",
       "      <td>0.028295</td>\n",
       "      <td>0.031878</td>\n",
       "      <td>0.046165</td>\n",
       "      <td>-0.005409</td>\n",
       "      <td>0.135404</td>\n",
       "      <td>-0.052996</td>\n",
       "      <td>-0.018056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127967</td>\n",
       "      <td>-0.000660</td>\n",
       "      <td>-0.006330</td>\n",
       "      <td>-0.017517</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>-0.011897</td>\n",
       "      <td>0.035845</td>\n",
       "      <td>0.022179</td>\n",
       "      <td>-0.117585</td>\n",
       "      <td>0.055960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571418</th>\n",
       "      <td>P692_0_1191</td>\n",
       "      <td>0.065206</td>\n",
       "      <td>-0.039234</td>\n",
       "      <td>0.128294</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>-0.005981</td>\n",
       "      <td>0.036254</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>0.081652</td>\n",
       "      <td>-0.068541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>0.016490</td>\n",
       "      <td>-0.003721</td>\n",
       "      <td>-0.015859</td>\n",
       "      <td>-0.056227</td>\n",
       "      <td>0.027022</td>\n",
       "      <td>0.054575</td>\n",
       "      <td>-0.036430</td>\n",
       "      <td>-0.086609</td>\n",
       "      <td>-0.061887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571419</th>\n",
       "      <td>P692_0_1192</td>\n",
       "      <td>-0.044050</td>\n",
       "      <td>-0.060684</td>\n",
       "      <td>-0.007178</td>\n",
       "      <td>-0.048807</td>\n",
       "      <td>-0.055611</td>\n",
       "      <td>-0.046039</td>\n",
       "      <td>0.013558</td>\n",
       "      <td>0.037443</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089439</td>\n",
       "      <td>-0.115163</td>\n",
       "      <td>-0.020040</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>-0.050863</td>\n",
       "      <td>0.056382</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>-0.047118</td>\n",
       "      <td>0.105796</td>\n",
       "      <td>0.012573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>571420 rows Ã— 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         segment_id      f000      f001      f002      f003      f004  \\\n",
       "0         PP572_0_1  0.009571  0.019323  0.007478  0.041222 -0.104351   \n",
       "1         PP572_0_2  0.063735 -0.090145  0.076856  0.016580 -0.015392   \n",
       "2         PP572_0_4 -0.009147  0.044874  0.095438  0.088864  0.026287   \n",
       "3         PP572_0_8  0.019812 -0.029717  0.070069  0.034346  0.003685   \n",
       "4         PP572_0_9  0.073630 -0.007963  0.084720  0.063671  0.041942   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "571415  P692_0_1186  0.021623 -0.037660  0.036766 -0.066743 -0.012067   \n",
       "571416  P692_0_1187 -0.013937 -0.014916  0.041315  0.013619  0.048789   \n",
       "571417  P692_0_1188 -0.041092  0.032440  0.028295  0.031878  0.046165   \n",
       "571418  P692_0_1191  0.065206 -0.039234  0.128294  0.013154 -0.005981   \n",
       "571419  P692_0_1192 -0.044050 -0.060684 -0.007178 -0.048807 -0.055611   \n",
       "\n",
       "            f005      f006      f007      f008  ...      f374      f375  \\\n",
       "0      -0.034637 -0.040082  0.048785 -0.049720  ...  0.016217  0.035958   \n",
       "1       0.004488 -0.014066 -0.021347 -0.007709  ... -0.104106  0.071222   \n",
       "2       0.003342  0.003761 -0.001537  0.002872  ... -0.008186 -0.041032   \n",
       "3       0.001872  0.164560  0.050357 -0.008711  ...  0.014106  0.020565   \n",
       "4       0.036758  0.003557  0.054233  0.024699  ... -0.025823 -0.039665   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "571415 -0.032461  0.029833  0.037347  0.053613  ... -0.062468  0.008806   \n",
       "571416 -0.042261  0.006820 -0.012841  0.032349  ...  0.046992 -0.001953   \n",
       "571417 -0.005409  0.135404 -0.052996 -0.018056  ... -0.127967 -0.000660   \n",
       "571418  0.036254  0.030744  0.081652 -0.068541  ... -0.000537  0.016490   \n",
       "571419 -0.046039  0.013558  0.037443  0.030121  ...  0.089439 -0.115163   \n",
       "\n",
       "            f376      f377      f378      f379      f380      f381      f382  \\\n",
       "0       0.039362 -0.010150 -0.011600  0.040785  0.031120  0.030377  0.008324   \n",
       "1       0.020406  0.048025  0.031107  0.021189  0.102623  0.039707  0.047844   \n",
       "2      -0.010027  0.012494  0.034509  0.038356  0.064894  0.012516  0.084423   \n",
       "3      -0.031883  0.069381 -0.025189 -0.059564 -0.057068 -0.010954  0.017886   \n",
       "4       0.044497  0.060275 -0.090286 -0.095973  0.009361 -0.100035  0.005244   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "571415 -0.059389  0.014321 -0.085285  0.089797 -0.038306  0.023783 -0.013505   \n",
       "571416 -0.058689 -0.005668  0.034324  0.031395 -0.075359  0.046120 -0.029264   \n",
       "571417 -0.006330 -0.017517  0.008965 -0.011897  0.035845  0.022179 -0.117585   \n",
       "571418 -0.003721 -0.015859 -0.056227  0.027022  0.054575 -0.036430 -0.086609   \n",
       "571419 -0.020040 -0.058825 -0.050863  0.056382  0.011649 -0.047118  0.105796   \n",
       "\n",
       "            f383  \n",
       "0      -0.058333  \n",
       "1       0.039239  \n",
       "2       0.010010  \n",
       "3      -0.061186  \n",
       "4      -0.068029  \n",
       "...          ...  \n",
       "571415  0.037073  \n",
       "571416  0.046044  \n",
       "571417  0.055960  \n",
       "571418 -0.061887  \n",
       "571419  0.012573  \n",
       "\n",
       "[571420 rows x 385 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = pd.read_csv('/cronus_data/rrao/WhiSBERT/embeddings/hitop_all-MiniLM-L12-v2.csv')\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Dense({'in_features': 768, 'out_features': 512, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"This is an example sentence.\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v1', cache_folder=CACHE_DIR)\n",
    "# model = torch.nn.DataParallel(model, device_ids=[1,2,3])\n",
    "embeddings = torch.from_numpy(model.encode(sentences))\n",
    "print(embeddings.shape)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8855)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].auto_model.config.num_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (layer): ModuleList(\n",
       "    (0-5): 6 x TransformerBlock(\n",
       "      (attention): MultiHeadSelfAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (ffn): FFN(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].auto_model.transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('activation_function', Tanh()),\n",
       "              ('linear',\n",
       "               Linear(in_features=768, out_features=512, bias=True))]),\n",
       " 'in_features': 768,\n",
       " 'out_features': 512,\n",
       " 'bias': True}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=512, bias=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tanh()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].activation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cronus_data/rrao/conda_envs/speech/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = WhiSBERTConfig(\n",
    "    whisper_model_id='openai/whisper-base',\n",
    "    pooling_mode='mean',\n",
    "    use_sbert_encoder=True,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    device='cuda'\n",
    ")\n",
    "processor, _, _, _ = load_models(config, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing AudioDataset...\n",
      "\tTotal dataset size (N): 50369\n",
      "\tTraining dataset size (N): 40295\n",
      "\tValidation dataset size (N): 10074\n"
     ]
    }
   ],
   "source": [
    "print('Preprocessing AudioDataset...')\n",
    "dataset = AudioDataset(processor)\n",
    "mini_size = int(0.1 * len(dataset))\n",
    "drop_size = len(dataset) - mini_size\n",
    "mini_dataset, _ = torch.utils.data.random_split(dataset, [mini_size, drop_size])\n",
    "\n",
    "# Calculate lengths for the train/val split (80:20)\n",
    "total_size = len(mini_dataset)\n",
    "train_size = int(0.8 * total_size)  # 80% for training\n",
    "val_size = total_size - train_size  # 20% for validation\n",
    "# Perform the split\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(mini_dataset, [train_size, val_size])\n",
    "print(f'\\tTotal dataset size (N): {total_size}')\n",
    "print(f'\\tTraining dataset size (N): {train_size}')\n",
    "print(f'\\tValidation dataset size (N): {val_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    shuffle=config.shuffle,\n",
    "    collate_fn=collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 80, 3000])\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(data_loader))\n",
    "print(batch['audio_inputs'].shape)\n",
    "print(len(batch['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(batch['text'], padding=True, truncation=True, return_tensors='pt').to(config.device)\n",
    "encoded_input['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 28, 768])\n",
      "torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sbert_output = sbert(**encoded_input)\n",
    "print(sbert_output.last_hidden_state.shape)\n",
    "sentence_embeddings = mean_pooling(sbert_output.last_hidden_state, encoded_input['attention_mask'])\n",
    "print(sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 22, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_output = sbert.embeddings(input_ids=encoded_input['input_ids'])#, attn_mask=encoded_input['attention_mask'])\n",
    "embedding_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 22, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_mask = [None] * sbert.config.num_hidden_layers\n",
    "encoder_output = sbert.transformer(\n",
    "    embedding_output,\n",
    "    attn_mask=torch.ones(encoded_input['input_ids'].size(), device=config.device),\n",
    "    head_mask=head_mask\n",
    ")[0]\n",
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = WhisperModel.from_pretrained(\n",
    "    config.whisper_model_id,\n",
    "    cache_dir=CACHE_DIR\n",
    ").to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 27])\n",
      "torch.Size([8, 27])\n"
     ]
    }
   ],
   "source": [
    "# Whisper-based tokenization\n",
    "with torch.no_grad():\n",
    "    outputs = processor.tokenizer(\n",
    "        batch['text'],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors='pt'\n",
    "    ).to(config.device)\n",
    "print(outputs['input_ids'].shape)\n",
    "print(outputs['attention_mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 27, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = whisper_model(\n",
    "    batch['audio_inputs'].to(config.device),\n",
    "    decoder_input_ids=outputs['input_ids'],\n",
    "    decoder_attention_mask=outputs['attention_mask']\n",
    ").last_hidden_state\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extended_attention_mask = sbert_model.get_extended_attention_mask(outputs['attention_mask'], whisper_embs.size()[:-1])\n",
    "# extended_attention_mask = sbert_model.get_extended_attention_mask(outputs['attention_mask'], outputs['attention_mask'].size())\n",
    "encoder_output = sbert_model.transformer(embedding_output, attn_mask=torch.ones(encoded_input['input_ids'].size(), device=config.device), head_mask=head_mask)[0]\n",
    "encoder_output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
